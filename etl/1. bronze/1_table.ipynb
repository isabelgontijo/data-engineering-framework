{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1bc968db-5b3a-4b21-ac24-39f8d3e95748",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# ðŸŸ« Bronze Layer - Table Ingestion Template\n",
    "\n",
    "This notebook is a standard template for ingesting raw data into the **Bronze layer** of our Lakehouse architecture using Databricks and Unity Catalog.\n",
    "\n",
    "It handles:\n",
    "- Extraction (full or incremental)\n",
    "- Serialization and standardization of data types\n",
    "- Quality validation (optional)\n",
    "- Writing to a Delta table (first-time or partition overwrite)\n",
    "- Metadata logging (record count, expectations, vacuum)\n",
    "- Optional table documentation (tags, notebook registration)\n",
    "\n",
    "---\n",
    "\n",
    "## How to use this template\n",
    "\n",
    "1. **Update the table name and path**\n",
    "   - Edit the `table = ...` line to set the correct target table.\n",
    "   - The `path` will be inferred automatically.\n",
    "\n",
    "2. **Implement your extraction logic**\n",
    "   - Based on the `w_first_write` flag, define full or incremental extraction.\n",
    "\n",
    "3. **Use the schema helper**\n",
    "   - When `w_debug = true`, a suggested schema for Silver typing will be printed.\n",
    "\n",
    "4. **Optional: Add more quality rules**\n",
    "   - You can extend the list of rules in the `Expectations` section.\n",
    "\n",
    "5. **Test in `dev` or `stg` environments first**\n",
    "   - Debug mode is automatically enabled in non-production.\n",
    "\n",
    "---\n",
    "\n",
    "## Widgets\n",
    "\n",
    "| Widget            | Description                                 | Default     |\n",
    "|-------------------|---------------------------------------------|-------------|\n",
    "| `w_reference_date`| Reference date for incremental loads        | Today       |\n",
    "| `w_first_write`   | Indicates full (true) or incremental (false)| false       |\n",
    "| `w_documentation` | Whether to apply table tags and register it | true        |\n",
    "| `w_debug`         | Enables debug prints and disables logging   | auto (env)  |\n",
    "| `w_quality`       | Enables application of quality rules        | true        |\n",
    "\n",
    "---\n",
    "\n",
    "## Table conventions\n",
    "\n",
    "- Tables must be in the format: `catalog.schema.table`\n",
    "- Bronze data is **typed as string** and **partitioned by `_created_at`**\n",
    "- Source structures (array, map, struct) are **serialized as JSON**\n",
    "- All writes append to Delta tables using partition overwrite\n",
    "\n",
    "---\n",
    "\n",
    "## Logging & Observability\n",
    "\n",
    "- `Expectations` will quarantine and log failing records (if enabled)\n",
    "- `RecordsQuantity` logs the amount of written rows\n",
    "- `VACUUM` retains 7 days of history by default\n",
    "- In production, notebook-to-table mapping is saved for lineage tracking\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3915f6fd-9f93-4cff-9be7-1dbe8bd44909",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "import src.utils as utils\n",
    "from src.notebook_context import notebook_context\n",
    "from src.expectations import Expectations\n",
    "from src.records_quantity import RecordsQuantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9b3952b-bebe-4aa3-a688-b17828fcaaa3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Notebook context\n",
    "notebook_vars = notebook_context()\n",
    "env = notebook_vars.get(\"env_folder\")\n",
    "catalog = env.split(\".\")[-1]\n",
    "notebook_path = notebook_vars.get(\"notebook_path\")\n",
    "\n",
    "# Default parameters\n",
    "today = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "default_debug = \"true\" if env in [\"dev\", \"stg\"] else \"false\"\n",
    "\n",
    "# Widgets declaration\n",
    "dbutils.widgets.text(\"w_reference_date\", today, \"Reference date (YYYY-MM-DD)\")\n",
    "dbutils.widgets.dropdown(\"w_first_write\", \"false\", [\"true\", \"false\"], \"First write?\")\n",
    "dbutils.widgets.dropdown(\"w_documentation\", \"true\", [\"true\", \"false\"], \"Apply documentation?\")\n",
    "dbutils.widgets.dropdown(\"w_debug\", default_debug, [\"true\", \"false\"], \"Debug mode?\")\n",
    "dbutils.widgets.dropdown(\"w_quality\", \"true\", [\"true\", \"false\"], \"Validate quality rules?\")\n",
    "\n",
    "# Widget values\n",
    "w_reference_date = utils.get_date_widget(\"w_reference_date\")\n",
    "w_first_write = utils.get_bool_widget(\"w_first_write\")\n",
    "w_documentation = utils.get_bool_widget(\"w_documentation\")\n",
    "w_debug = utils.get_bool_widget(\"w_debug\")\n",
    "w_quality = utils.get_bool_widget(\"w_quality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9bd789bb-8f6e-441c-8832-dcf61f6ae2c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Update with the correct table name in the format: <catalog>.<schema>.<table_name>\n",
    "table = f\"{catalog}.source_bronze.table\"\n",
    "\n",
    "# Parse table components\n",
    "parts = table.split(\".\")\n",
    "if len(parts) != 3:\n",
    "    raise ValueError(f\"[config] Invalid table format: '{table}'. Expected format: '<catalog>.<schema>.<table>'\")\n",
    "\n",
    "catalog, schema, table_name = parts\n",
    "path = f\"Volumes/{catalog}/{schema}/{table_name}/\"\n",
    "\n",
    "utils.formatted_print(f\"[config] Table: {table}\", debug=w_debug)\n",
    "utils.formatted_print(f\"[config] Path: {path}\", debug=w_debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9a98e80-1635-4e68-9f5f-8dcfd39330c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if w_first_write:\n",
    "    # TODO: Implement full extraction logic\n",
    "    utils.formatted_print(\"[extract] Full extraction triggered\", debug=w_debug)\n",
    "    df = ...  # full load\n",
    "else:\n",
    "    # TODO: Implement incremental extraction logic\n",
    "    utils.formatted_print(\"[extract] Incremental extraction triggered\", debug=w_debug)\n",
    "    df = ...  # incremental load\n",
    "\n",
    "utils.debug_df(df, debug=w_debug, label=\"Raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7142290-89af-42e6-bd47-b7e441702be2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for col_name in df.columns:\n",
    "    data_type = df.schema[col_name].dataType\n",
    "\n",
    "    if isinstance(data_type, (T.ArrayType, T.MapType, T.StructType)):\n",
    "        df = df.withColumn(col_name, F.to_json(F.col(col_name)))\n",
    "        utils.formatted_print(f\"[typing] Column '{col_name}' ({data_type}) -> serialized to JSON\", debug=w_debug, force_debug_only=True)\n",
    "    else:\n",
    "        df = df.withColumn(col_name, F.col(col_name).cast(\"string\"))\n",
    "        utils.formatted_print(f\"[typing] Column '{col_name}' ({data_type}) -> casted to string\", debug=w_debug, force_debug_only=True)\n",
    "\n",
    "utils.debug_df(df, debug=w_debug, label=\"Typed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ef257811-5461-4f44-8de4-242ca29c68ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pattern = r'\\b(?!Array|Map|Struct)(\\w+Type\\(\\))'\n",
    "modified_schema = re.sub(pattern, 'StringType()', str(df.schema))\n",
    "\n",
    "utils.formatted_print(f\"\\n[debug/schema]\\n> Suggested schema for Silver typing (convert all simple types to StringType):\\n{modified_schema}\", debug=w_debug, force_debug_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a36af833-269b-4434-b1dc-ecec72a2a4d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df.withColumns({\n",
    "    \"_created_at\": F.current_timestamp(),\n",
    "    # \"_source_file\": F.input_file_name(),  # TODO: Uncomment if reading from files (e.g., CSV, Parquet)\n",
    "})\n",
    "\n",
    "utils.debug_df(df, debug=w_debug, label=\"Final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e6611b8-5120-4227-bb5c-d8b42ac002f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if w_quality:\n",
    "    rules = [\n",
    "        {\"scenario\": \"is_not_empty\"}\n",
    "    ]\n",
    "\n",
    "    Expectations(\n",
    "        df=df,\n",
    "        table_name=table,\n",
    "        debug=w_debug,\n",
    "        save_log=not w_debug,\n",
    "        raise_exception=True,\n",
    "        quarantine=True\n",
    "    ).apply(rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a46cdc2-3d6d-4b5e-a008-f475c9e95f8c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "utils.formatted_print(f\"[write] Writing table: {table} | Mode: {'full' if w_first_write else 'incremental'}\", debug=w_debug)\n",
    "\n",
    "if w_first_write:\n",
    "    # Full write: create table with schema and path\n",
    "    (df.write\n",
    "        .mode(\"overwrite\")\n",
    "        .partitionBy(\"_created_at\")\n",
    "        .option(\"overwriteSchema\", \"true\")\n",
    "        .option(\"path\", path)\n",
    "        .saveAsTable(table)\n",
    "    )\n",
    "    utils.formatted_print(f\"[write] Table created at path: {path}\", debug=w_debug)\n",
    "\n",
    "    # Register table <-> notebook (only in prod)\n",
    "    if env == '3.prd':\n",
    "        utils.register_table_notebook(table, notebook_path, debug=w_debug)\n",
    "\n",
    "else:\n",
    "    # Incremental write: overwrite based on date partition\n",
    "    utils.formatted_print(f\"[write] Overwriting partition: _created_at = {w_reference_date}\", debug=w_debug)\n",
    "\n",
    "    (df.write\n",
    "        .mode(\"overwrite\")\n",
    "        .option(\"replaceWhere\", f\"_created_at = '{w_reference_date}'\")\n",
    "        .saveAsTable(table)\n",
    "    )\n",
    "\n",
    "# Collect number of records written\n",
    "RecordsQuantity(table_name=table, debug=w_debug, save_log=not w_debug).save()\n",
    "\n",
    "utils.formatted_print(f\"[vacuum] Executing VACUUM on table {table} (168 hours retention)\", debug=w_debug)\n",
    "spark.sql(f\"VACUUM {table} RETAIN 168 HOURS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "51a14f2a-c732-46d6-9cc2-a94a7ff98453",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if w_documentation:\n",
    "    utils.formatted_print(\"[documentation] Applying table tags...\", debug=w_debug)\n",
    "\n",
    "    tags = {\n",
    "        \"source\": \"\",\n",
    "        \"domain\": \"\",\n",
    "        \"owner\": \"\",\n",
    "        \"criticality\": \"\",\n",
    "        \"retention_policy\": \"\"\n",
    "    }\n",
    "\n",
    "    utils.apply_table_tags(table=table, tags=tags, debug=w_debug)\n",
    "\n",
    "    utils.formatted_print(\"[documentation] Tagging completed\", debug=w_debug)\n",
    "\n",
    "    if w_debug:\n",
    "        tags_applied = (\n",
    "            spark.sql(f\"DESCRIBE TABLE EXTENDED {table}\")\n",
    "                .filter(\"col_name = 'Table Properties'\")\n",
    "                .select(\"data_type\").collect()\n",
    "            )\n",
    "        print(\"[debug] Applied table tags:\")\n",
    "        for row in tags_applied:\n",
    "            print(row[\"data_type\"])"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "1_table",
   "widgets": {
    "w_debug": {
     "currentValue": "true",
     "nuid": "d4c77b71-c0ef-424e-af6c-35ab2c3bd274",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "false",
      "label": "Debug mode?",
      "name": "w_debug",
      "options": {
       "widgetDisplayType": "Dropdown",
       "choices": [
        "true",
        "false"
       ],
       "fixedDomain": true,
       "multiselect": false
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "dropdown",
      "defaultValue": "false",
      "label": "Debug mode?",
      "name": "w_debug",
      "options": {
       "widgetType": "dropdown",
       "autoCreated": null,
       "choices": [
        "true",
        "false"
       ]
      }
     }
    },
    "w_documentation": {
     "currentValue": "true",
     "nuid": "46984a9e-4c43-45a0-a4a8-09a1a13e8938",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "true",
      "label": "Apply documentation?",
      "name": "w_documentation",
      "options": {
       "widgetDisplayType": "Dropdown",
       "choices": [
        "true",
        "false"
       ],
       "fixedDomain": true,
       "multiselect": false
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "dropdown",
      "defaultValue": "true",
      "label": "Apply documentation?",
      "name": "w_documentation",
      "options": {
       "widgetType": "dropdown",
       "autoCreated": null,
       "choices": [
        "true",
        "false"
       ]
      }
     }
    },
    "w_first_write": {
     "currentValue": "false",
     "nuid": "7130080d-f07f-4520-bb3a-252253dcfc78",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "false",
      "label": "First write?",
      "name": "w_first_write",
      "options": {
       "widgetDisplayType": "Dropdown",
       "choices": [
        "true",
        "false"
       ],
       "fixedDomain": true,
       "multiselect": false
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "dropdown",
      "defaultValue": "false",
      "label": "First write?",
      "name": "w_first_write",
      "options": {
       "widgetType": "dropdown",
       "autoCreated": null,
       "choices": [
        "true",
        "false"
       ]
      }
     }
    },
    "w_quality": {
     "currentValue": "true",
     "nuid": "80b559b2-c5ff-442a-a2c2-66095ca42496",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "true",
      "label": "Validate quality rules?",
      "name": "w_quality",
      "options": {
       "widgetDisplayType": "Dropdown",
       "choices": [
        "true",
        "false"
       ],
       "fixedDomain": true,
       "multiselect": false
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "dropdown",
      "defaultValue": "true",
      "label": "Validate quality rules?",
      "name": "w_quality",
      "options": {
       "widgetType": "dropdown",
       "autoCreated": null,
       "choices": [
        "true",
        "false"
       ]
      }
     }
    },
    "w_reference_date": {
     "currentValue": "2025-06-20",
     "nuid": "92602793-e2a6-48ff-85b1-92ad8fbd37e6",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "2025-06-20",
      "label": "Reference date (YYYY-MM-DD)",
      "name": "w_reference_date",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "2025-06-20",
      "label": "Reference date (YYYY-MM-DD)",
      "name": "w_reference_date",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
